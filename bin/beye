#!/bin/env python

# Copyright 2013 by László Nagy
# This file is part of Beye [see file LICENSE.txt for more]

import os
import logging
import multiprocessing


def main():
    from argparse import ArgumentParser
    parser = ArgumentParser()
    parser.add_argument("--output",
                        metavar='DIR',
                        help="Specify output directory\
                              (default generated)")
    parser.add_argument("--input",
                        metavar='FILE',
                        default="compile_commands.json",
                        help="The JSON compilation database\
                              (default compile_commands.json)")
    parser.add_argument('--log-level',
                        metavar='LEVEL',
                        choices='DEBUG INFO WARN ERROR'.split(),
                        default='WARN',
                        help="Choose a log level from DEBUG, INFO, WARN,\
                              (default) or ERROR")
    args = parser.parse_args()

    logging.basicConfig(format='%(levelname)s: %(message)s', level=args.log_level)

    try:
        out_dir = create_out_directory(args.output)
        with open(args.input, "r") as fd:
            import json
            parallel(json.load(fd), analyze, merge, None)
    finally:
        cleanup_out_directory(out_dir)


def analyze(input):
    import subprocess
    cmd = input['command'].split(' ')
    cmd[0] = '/usr/lib/clang-analyzer/scan-build/ccc-analyzer'
    logging.debug('executing: {}'.format(cmd))
    compilation = subprocess.Popen(cmd)
    compilation.wait()
    return compilation.returncode


def merge(results, result):
    return


def create_out_directory(hint):
    if (hint):
        try:
            os.mkdir(hint)
        except OSError as ex:
            if ex.errno != 17: # Already exists
                raise

        result = hint
    else:
        import tempfile
        result = tempfile.mkdtemp(prefix='beye-')

    logging.debug('output directory: {}'.format(result))
    return result


def cleanup_out_directory(dir):
    try:
        os.removedirs(dir)
    except OSError as ex:
        if ex.errno != 39: # Directory not empty
            raise


# mini map-reduce framework
def _produce_to_queue(func, queue, task):
    queue.put(func(task))


def _consume_from_queue(func, queue, result):
    for e in iter(queue.get, 'STOP'):
        func(result, e)


def parallel(input_iterable, produce_func, consume_func, output):
    import threading
    queue = multiprocessing.Manager().Queue()

    consumer = threading.Thread(target=_consume_from_queue,
                                args=(consume_func, queue, output))
    consumer.start()

    pool = multiprocessing.Pool()
    for task in input_iterable:
        pool.apply_async(func=_produce_to_queue,
                         args=(produce_func, queue, task))
    pool.close()
    pool.join()

    queue.put('STOP')
    consumer.join()

    return output


# entry symbol
if __name__ == '__main__':
    multiprocessing.freeze_support()
    main()
